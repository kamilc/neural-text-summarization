{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import spacy\n",
    "from cached_property import cached_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\n",
    "    \"en_core_web_lg\",\n",
    "    disable=[\"tagger\", \"ner\", \"textcat\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_parquet(\"data/articles-processed.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        \"\"\"\n",
    "        The forward pass for the network\n",
    "        \n",
    "        hidden_state : tensor (batch_num, hidden_size)\n",
    "        \n",
    "        returns         : tensor (batch_num, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizeNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SummarizeNet, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, word_embeddings, generate=\"sentence\"):\n",
    "        \"\"\"\n",
    "        The forward pass for the network\n",
    "        \n",
    "        word_embeddings : tensor (batch_num, max_seq_len, vocab_len)\n",
    "        \n",
    "        returns         : tuple (\n",
    "                            tensor (batch_num, max_seq_len, vocab_len),\n",
    "                            tensor (batch_num, hidden_size)\n",
    "                          )\n",
    "        \n",
    "        First tensor in the returning tuple is a probability over the vocabulary\n",
    "        for each sequence position\n",
    "        \n",
    "        The second tensor is an encoder's hidden state \n",
    "        \"\"\"\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_title</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nGet a bachelor’s degree.,\\nEnroll in a studi...</td>\n",
       "      <td>It is possible to become a VFX artist without...</td>\n",
       "      <td>HowtoBeaVisualEffectsArtist1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nKeep your reference materials, sketches, art...</td>\n",
       "      <td>As you start planning for a project or work, ...</td>\n",
       "      <td>HowtoBeanOrganizedArtist2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nCreate a compelling reel or portfolio.,\\nLan...</td>\n",
       "      <td>This should be a short video showcasing the b...</td>\n",
       "      <td>HowtoBeaVisualEffectsArtist2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nJoin a professional society.,\\nEnjoy working...</td>\n",
       "      <td>Networking is a great way to find new opportu...</td>\n",
       "      <td>HowtoBeaVisualEffectsArtist3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nMake a list of what your friends watch, read...</td>\n",
       "      <td>Use your friends’ conversations to figure out...</td>\n",
       "      <td>HowtoAlwaysCatchPopCultureReferences1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215359</th>\n",
       "      <td>\\nUse a childhood nickname.,\\nUse your middle ...</td>\n",
       "      <td>You may have been called something other than...</td>\n",
       "      <td>HowtoPickaStageName2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215360</th>\n",
       "      <td>\\nConsider changing the spelling of your name....</td>\n",
       "      <td>If you have a name that you like, you might f...</td>\n",
       "      <td>HowtoPickaStageName3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215361</th>\n",
       "      <td>\\nTry out your name.,\\nDon’t legally change yo...</td>\n",
       "      <td>Your name might sound great to you when you s...</td>\n",
       "      <td>HowtoPickaStageName4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215362</th>\n",
       "      <td>\\nUnderstand the process of relief printing.,\\...</td>\n",
       "      <td>Relief printing is the oldest and most tradit...</td>\n",
       "      <td>HowtoIdentifyPrints1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215363</th>\n",
       "      <td>\\nUnderstand the process of intaglio printing....</td>\n",
       "      <td>Intaglio is Italian for \"incis­ing,\" and corr...</td>\n",
       "      <td>HowtoIdentifyPrints2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "index                                                       \n",
       "2       \\nGet a bachelor’s degree.,\\nEnroll in a studi...   \n",
       "4       \\nKeep your reference materials, sketches, art...   \n",
       "6       \\nCreate a compelling reel or portfolio.,\\nLan...   \n",
       "7       \\nJoin a professional society.,\\nEnjoy working...   \n",
       "9       \\nMake a list of what your friends watch, read...   \n",
       "...                                                   ...   \n",
       "215359  \\nUse a childhood nickname.,\\nUse your middle ...   \n",
       "215360  \\nConsider changing the spelling of your name....   \n",
       "215361  \\nTry out your name.,\\nDon’t legally change yo...   \n",
       "215362  \\nUnderstand the process of relief printing.,\\...   \n",
       "215363  \\nUnderstand the process of intaglio printing....   \n",
       "\n",
       "                                                     text  \\\n",
       "index                                                       \n",
       "2        It is possible to become a VFX artist without...   \n",
       "4        As you start planning for a project or work, ...   \n",
       "6        This should be a short video showcasing the b...   \n",
       "7        Networking is a great way to find new opportu...   \n",
       "9        Use your friends’ conversations to figure out...   \n",
       "...                                                   ...   \n",
       "215359   You may have been called something other than...   \n",
       "215360   If you have a name that you like, you might f...   \n",
       "215361   Your name might sound great to you when you s...   \n",
       "215362   Relief printing is the oldest and most tradit...   \n",
       "215363   Intaglio is Italian for \"incis­ing,\" and corr...   \n",
       "\n",
       "                             normalized_title    set  \n",
       "index                                                 \n",
       "2                HowtoBeaVisualEffectsArtist1  train  \n",
       "4                   HowtoBeanOrganizedArtist2  train  \n",
       "6                HowtoBeaVisualEffectsArtist2  train  \n",
       "7                HowtoBeaVisualEffectsArtist3  train  \n",
       "9       HowtoAlwaysCatchPopCultureReferences1  train  \n",
       "...                                       ...    ...  \n",
       "215359                   HowtoPickaStageName2  train  \n",
       "215360                   HowtoPickaStageName3  train  \n",
       "215361                   HowtoPickaStageName4  train  \n",
       "215362                   HowtoIdentifyPrints1  train  \n",
       "215363                   HowtoIdentifyPrints2  train  \n",
       "\n",
       "[130414 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesDataset(Dataset):\n",
    "    def __init__(self, dataframe, mode, transforms=[]):\n",
    "        self.data = dataframe[dataframe.set == mode]\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2*len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        _idx = []\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            _idx = idx.tolist()\n",
    "        \n",
    "        if isinstance(idx, list):\n",
    "            _idx = idx\n",
    "        else:\n",
    "            _idx = [ idx ]\n",
    "        \n",
    "        _ids = [ (i - (i % 2))/2 for i in _idx]\n",
    "\n",
    "        data = self.data.iloc[_ids, :]\n",
    "        data['asked_id'] = _idx\n",
    "        \n",
    "        data = pd.DataFrame(\n",
    "            {\n",
    "                'set': [self.mode for _ in range(0, len(_ids))],\n",
    "                'mode': [ (0 if i % 2 == 0 else 1) for i in _idx ],\n",
    "                'text': data.apply(lambda row: row['text'] if row['asked_id'] % 2 == 0 else row['headline'], axis=1),\n",
    "                'title': data['normalized_title']\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for transform in self.transforms:\n",
    "            data = transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToParsedDoc(object):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        sample['doc'] = sample.apply(lambda row: self.nlp(row['text']), axis=1)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsToVectors(object):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        sample['word_embeddings'] = sample.apply(\n",
    "            lambda row: np.stack([token.vector for token in row['doc']]),\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoiseToEmbeddings(object):\n",
    "    def __init__(self, probability_of_mask_for_word):\n",
    "        self.probability_of_mask_for_word = probability_of_mask_for_word\n",
    "        self.rng = np.random.default_rng()\n",
    "        \n",
    "    def mask_vector(self, vector):\n",
    "        \"\"\"\n",
    "        Masks words with zeros randomly\n",
    "        \"\"\"\n",
    "        seq_len = vector.shape[0]\n",
    "        vector_len = vector.shape[1]\n",
    "        \n",
    "        mask = np.repeat(\n",
    "            self.rng.choice(\n",
    "                [0, 1],\n",
    "                seq_len,\n",
    "                p=[\n",
    "                    self.probability_of_mask_for_word,\n",
    "                    (1 - self.probability_of_mask_for_word)\n",
    "                ]\n",
    "            ).reshape((seq_len, 1)),\n",
    "            vector_len,\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return vector * mask\n",
    "        \n",
    "    def __call__(self, sample):       \n",
    "        sample['noisy_word_embeddings'] = sample['word_embeddings'].apply(self.mask_vector)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeBatch(object):\n",
    "    def stack_vectors(self, vectors):\n",
    "        max_seq = max([vector.shape[0] for vector in vectors])\n",
    "        \n",
    "        return np.stack(\n",
    "            [\n",
    "                np.pad(vector, [(0, max_seq - vector.shape[0]), (0, 0)])\n",
    "                for vector in vectors\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        del sample['doc']\n",
    "        \n",
    "        sample = sample.to_dict(orient=\"list\")\n",
    "        \n",
    "        sample['word_embeddings'] = self.stack_vectors(sample['word_embeddings'])\n",
    "        sample['noisy_word_embeddings'] = self.stack_vectors(sample['noisy_word_embeddings'])\n",
    "    \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'set': ['train', 'train', 'train', 'train', 'train'],\n",
       " 'mode': [0, 1, 0, 1, 0],\n",
       " 'text': [' It is possible to become a VFX artist without a college degree, but the path is often easier with one. VFX artists usually major in fine arts, computer graphics, or animation. Choose a college with a reputation for strength in these areas and a reputation for good job placement for graduates. The availability of internships is another factor to consider.Out of the jobs advertised for VFX artists, a majority at any given time specify a bachelor’s degree as a minimum requirement for applicants.;\\n, Some studios offer short-term programs for people who want to learn more about VFX artistry without pursuing a college degree. Enrolling in these programs can be expensive as financial aid isn’t always offered, but they usually have the most cutting edge technology for you to learn from., Although you may create some hand sketches, the majority of your work will be completed on the computer using the most up-to-date programs. Stay informed about the newest software advances by following VFX blogs and taking online computer tutorials.For example, VFX artists are expected to be well-versed in graphics and animation programs, such as Adobe Creative Suite and JavaScript.Clearly list every program that you can work with on your resume.\\n\\n, Hop onto YouTube or another video service and search for VFX clip reels or demonstrations. Some of these videos will focus on a particular skill set, such as shading, which you then can practice on your own. Challenge yourself to mimic some of the more difficult tasks, or even try to improve upon the models used., Take as many art and design classes as you can. Or, simply carry a sketch pad around with you to work on your basic animation skills. As you draw, consider factors such as lighting and framing. Even geometry skills can come in handy when creating a particular type of background or even a person’s face.Make a choice to become an observer of the world around you. Ask yourself: how could I capture the movement of the leaves? Or, in what situations do shadows appear?\\n\\n, Watch all of these creations with an eye for detail. Look for the techniques used and any original approaches that you see. Try to recreate any scenes that you find particularly interesting. Research the artists and see what their backgrounds are and contact them if you like., As you gain more experience, you’ll likely find yourself gravitating toward a certain aspect of design. This will become your “calling card” and directors and other professionals will seek you out for this type of work. To build your specialization, start choosing jobs with that emphasis and attend additional training seminars.For example, some VFX specialists focus on human character’s faces, animal figures, or city backgrounds.\\n\\n',\n",
       "  '\\nGet a bachelor’s degree.,\\nEnroll in a studio-based program.,\\nTrain on a number of VFX computer programs.,\\nWatch online tutorials.,\\nNurture your artistic side.,\\nPay close attention to movies, television shows, and video games.,\\nDevelop a specialization.',\n",
       "  ' As you start planning for a project or work, you\\'ll likely be gathering scraps of inspiration and test sketches. While everyone has a strategy, there is nothing more maddening than digging through a book or the internet to re-find the cool idea you saw three months ago. Try out:\\n\\n\\nDedicating 1 notebook, preferably with insert folders, to each project.\\nMaking a bookmark folder for each project on your internet browser to easily compile online inspiration.\\nTacking up physical inspiration on a wall or cork board near your workspace., Very few artists simply dive right into large projects. Almost 100% of the time they instead work on related, smaller projects called \"studies\" to prepare for the larger work. You might practice the face of the portrait you\\'re making, sketch our different composition ideas, or practice a vulnerable or difficult part of a sculpture. Keep these organized as a way to prepare both the skills, ideas, and supplies needed for the final project.\\n\\n, At the end of the day, artists are visual people, and tucking everything away neatly and cleanly may not be conducive to the artistic process. Of course, neither is losing or misplacing essential supplies. Find a compromise by packing away any supplies not currently in use, and leaving a little bit of \"essential\" clutter. It\\'s okay to have inspiration scattered around the studio -- just make sure it\\'s the inspiration you need for the current project.\\n\\n\\nJust because you \"aren\\'t organized\" is no excuse not to make an attempt. Don\\'t feel like the only options are perfect cleanliness or an utter mess-- there is a middle ground.\\n\\n, Nothing is worse than spending a long night on a painting only to realize you\\'ve run out of white paint halfway through a section. Once a week, or more frequently if possible, check in on the quantities of your supplies so that you can refill them before it becomes a problem.\\n\\n\\nA simple spreadsheet or notebook, marked at the end of each artistic session, is a quick and easy way to keep tabs on your stuff.\\n\\n, Deciding to paint a mural is a huge undertaking. But sketching the idea, transposing the image onto the wall, painting the basic colors, then adding shading/detail are four separate and more manageable projects. Organization is key to big projects, even if it feels \"constraining\" to your creativity. In reality, organizing your work and progress frees your mind to actually be creative, instead of worrying about logistics.\\n\\n\\nFigure out the building blocks of each part of the project, tackling each at once. Don\\'t jump around across all parts of the project haphazardly.\\n\\n',\n",
       "  '\\nKeep your reference materials, sketches, articles, photos, etc, in one easy to find place.,\\nMake \"studies,\" or practice sketches, to organize effectively for larger projects.,\\nLimit the supplies you leave out to the project at hand.,\\nKeep an updated list of all of the necessary supplies, and the quantities of each.,\\nBreak down bigger works into more easily completed parts.',\n",
       "  ' This should be a short video showcasing the breadth and depth of your skills as an artist. Some choose to follow a storyline format while others cycle through a series of clips. Most college programs will give you time to create this work in your junior or senior years using professional grade equipment and software.Your reel is also a chance for you to showcase any unique skills that you possess, such as drawing or sculpting.Don’t be afraid to work with other artists to create your reel. Showing that you can collaborate well with others is something that studios often look for when hiring.\\n\\n, If you are enrolled in a VFX program, talk to your career counselors to see what opportunities might be available. If you are developing your skills on your own, reach out to studios to see if they have any spots for paid or unpaid interns. This will give a potential employer a chance to get to know you and might make it easier for them to hire you in the future., Over half of VFX artists are their own bosses. Being a freelance designer gives you more control over your schedule and project selection. But, it also means that you will need to handle administrative tasks and could struggle with bringing in a consistent income.If this path interests you, it would be wise to take a few classes in marketing and accounting. Getting established is a hard struggle that many self-employed artists face.Choosing your own projects can mean that you’ll establish a specialty more quickly than you might in a large studio. However, affording the most recent design equipment may be tough, depending on how successful you are.\\n\\n, This is a more traditional option where you agree to full or part-time employment with an established company. Your work schedule and salary will very much depend on the prominence of the company and the types of projects that come in. However, you may get the opportunity to work on some big Hollywood blockbusters or top-rated television shows!Get your foot in the door of larger companies by serving as a junior 2D artist or runner. A junior artist will assist those with seniority by creating basic outlines for scenery and the like. A runner literally runs sketches and communications between the VFX team and a director, for example., With enough time, effort, and luck, you may get the chance to take on a leadership position for a project. As a supervisor, the final product that audiences see is your responsibility. You’ll take all of the raw images and make them fit together while working alongside the production team.'],\n",
       " 'title': ['HowtoBeaVisualEffectsArtist1',\n",
       "  'HowtoBeaVisualEffectsArtist1',\n",
       "  'HowtoBeanOrganizedArtist2',\n",
       "  'HowtoBeanOrganizedArtist2',\n",
       "  'HowtoBeaVisualEffectsArtist2'],\n",
       " 'word_embeddings': array([[[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.0013629,  0.35653  , -0.055497 , ..., -0.11237  ,\n",
       "           0.078259 ,  0.22398  ],\n",
       "         [-0.084961 ,  0.502    ,  0.0023823, ..., -0.21511  ,\n",
       "          -0.26304  , -0.0060173],\n",
       "         ...,\n",
       "         [ 0.15687  , -0.18112  ,  0.20469  , ...,  0.18724  ,\n",
       "           0.095485 ,  0.39767  ],\n",
       "         [ 0.012001 ,  0.20751  , -0.12578  , ...,  0.13871  ,\n",
       "          -0.36049  , -0.035    ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       " \n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [-0.26879  ,  0.17483  , -0.35633  , ..., -0.17138  ,\n",
       "           0.26846  ,  0.19866  ],\n",
       "         [ 0.043798 ,  0.024779 , -0.20937  , ..., -0.30099  ,\n",
       "          -0.14584  ,  0.28188  ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       " \n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [-0.10648  , -0.016295 , -0.22755  , ..., -0.31343  ,\n",
       "           0.087424 , -0.1661   ],\n",
       "         [-0.11076  ,  0.30786  , -0.5198   , ..., -0.059105 ,\n",
       "           0.47604  ,  0.05661  ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       " \n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [-0.0041277, -0.059674 , -0.51836  , ..., -0.16482  ,\n",
       "          -0.075328 , -0.32515  ],\n",
       "         [-0.11872  ,  0.36208  , -0.54429  , ...,  0.054371 ,\n",
       "           0.24781  , -0.0055343],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       " \n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [-0.087595 ,  0.35502  ,  0.063868 , ...,  0.03446  ,\n",
       "          -0.15027  ,  0.40673  ],\n",
       "         [-0.013048 ,  0.066305 , -0.18675  , ..., -0.53575  ,\n",
       "           0.34552  ,  0.038396 ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]]], dtype=float32),\n",
       " 'noisy_word_embeddings': array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.0013629 ,  0.35653001, -0.055497  , ..., -0.11237   ,\n",
       "           0.078259  ,  0.22397999],\n",
       "         [-0.        ,  0.        ,  0.        , ..., -0.        ,\n",
       "          -0.        , -0.        ],\n",
       "         ...,\n",
       "         [ 0.15686999, -0.18111999,  0.20468999, ...,  0.18724   ,\n",
       "           0.095485  ,  0.39767   ],\n",
       "         [ 0.012001  ,  0.20750999, -0.12578   , ...,  0.13871001,\n",
       "          -0.36048999, -0.035     ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.26879001,  0.17483   , -0.35633001, ..., -0.17138   ,\n",
       "           0.26846001,  0.19866   ],\n",
       "         [ 0.043798  ,  0.024779  , -0.20937   , ..., -0.30098999,\n",
       "          -0.14584   ,  0.28187999],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "           0.        , -0.        ],\n",
       "         [-0.        ,  0.        , -0.        , ..., -0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.0041277 , -0.059674  , -0.51836002, ..., -0.16482   ,\n",
       "          -0.075328  , -0.32515001],\n",
       "         [-0.11872   ,  0.36208001, -0.54429001, ...,  0.054371  ,\n",
       "           0.24781001, -0.0055343 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.087595  ,  0.35501999,  0.063868  , ...,  0.03446   ,\n",
       "          -0.15027   ,  0.40673   ],\n",
       "         [-0.013048  ,  0.066305  , -0.18674999, ..., -0.53574997,\n",
       "           0.34551999,  0.038396  ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArticlesDataset(\n",
    "    articles,\n",
    "    mode=\"train\",\n",
    "    transforms=[\n",
    "        TextToParsedDoc(nlp),\n",
    "        WordsToVectors(nlp),\n",
    "        AddNoiseToEmbeddings(0.2),\n",
    "        MergeBatch()\n",
    "    ]\n",
    ")[[0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 180 and 45 in dimension 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:612\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b54eb3bb0e7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )))\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 180 and 45 in dimension 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:612\n"
     ]
    }
   ],
   "source": [
    "next(iter(DataLoader(\n",
    "    ArticlesDataset(\n",
    "        articles,\n",
    "        mode=\"train\",\n",
    "        transforms=[\n",
    "            TextToParsedDoc(nlp),\n",
    "            WordsToVectors(nlp),\n",
    "            AddNoiseToEmbeddings(0.2),\n",
    "            MergeBatch()\n",
    "        ]\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesBatch:\n",
    "    def __init__(self, data, id):\n",
    "        self.data = data\n",
    "        self.id = id\n",
    "        \n",
    "    def __getattr__(self, name):\n",
    "        if name in self.data:\n",
    "            return self.data[name]\n",
    "        else:\n",
    "            raise AttributeError(f\"Attribute missing: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTrainer:\n",
    "    def __init__(self, name, nlp,\n",
    "                 summarize_model, discriminate_model, dataframe,\n",
    "                 batch_size, update_every, save_every, loader_workers,\n",
    "                 probability_of_mask_for_word,\n",
    "                 lambda_article, lambda_sentence):\n",
    "        self.name = name\n",
    "        \n",
    "        self.datasets = {\n",
    "            \"train\": ArticlesDataset(\n",
    "                dataframe,\n",
    "                \"train\",\n",
    "                transforms=[\n",
    "                    TextToParsedDoc(nlp),\n",
    "                    WordsToVectors(nlp),\n",
    "                    AddNoiseToEmbeddings(probability_of_mask_for_word),\n",
    "                    MergeBatch()\n",
    "                ]\n",
    "            ),\n",
    "            \"test\":  ArticlesDataset(\n",
    "                dataframe,\n",
    "                \"test\",\n",
    "                transforms=[\n",
    "                    TextToParsedDoc(nlp),\n",
    "                    WordsToVectors(nlp),\n",
    "                    AddNoiseToEmbeddings(0),\n",
    "                    MergeBatch()\n",
    "                ]\n",
    "            ),\n",
    "            \"eval\":  ArticlesDataset(\n",
    "                dataframe,\n",
    "                \"eval\",\n",
    "                transforms=[\n",
    "                    TextToParsedDoc(nlp),\n",
    "                    WordsToVectors(nlp),\n",
    "                    AddNoiseToEmbeddings(0),\n",
    "                    MergeBatch()\n",
    "                ]\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.update_every = update_every\n",
    "        self.save_every = save_every\n",
    "        self.loader_workers = loader_workers\n",
    "        \n",
    "        self.summarize_model = summarize_model\n",
    "        self.discriminate_model = discriminate_model\n",
    "        \n",
    "        self.lambda_article = lambda_article\n",
    "        self.lambda_sentence = lambda_sentence\n",
    "        \n",
    "        self.current_batch_id = 0\n",
    "        \n",
    "    @property\n",
    "    def models(self):\n",
    "        return self.summarize_model, self.discriminate_model\n",
    "    \n",
    "    def save(self):\n",
    "        checkpoint_path = f\"checkpoints/{self.name}/batch-#{self.current_batch_id}\"\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "        \n",
    "        torch.save(\n",
    "            {\n",
    "                'current_batch_id': self.current_batch_id,\n",
    "                'batch_size': self.batch_size,\n",
    "                'update_every': self.update_every,\n",
    "                'save_every': self.save_every,\n",
    "                'lambda_article': self.lambda_article,\n",
    "                'lambda_sentence': self.lambda_sentence,\n",
    "                'summarize_model_state': self.summarize_model.state_dict(),\n",
    "                'discriminate_model_state': self.discriminate_model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict()\n",
    "            },\n",
    "            f\"{checkpoint_path}/state.pth\"\n",
    "        )\n",
    "        \n",
    "    def load(name, dataframe):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def batches(self, mode):\n",
    "        start_id = self.current_batch_id\n",
    "        \n",
    "        while True:\n",
    "            loader = DataLoader(\n",
    "                self.datasets[mode],\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=self.loader_workers\n",
    "            )\n",
    "\n",
    "            for ix, data in enumerate(loader):\n",
    "                self.current_batch_id += ix\n",
    "                \n",
    "                yield(\n",
    "                    ArticlesBatch(\n",
    "                        data,\n",
    "                        id=self.current_batch_id\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "    \n",
    "    def batch_loss(self, batch):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def after_update(self, batch, loss_sum):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        batches = self.batches(\"train\")\n",
    "        loss_sum = 0\n",
    "        \n",
    "        for batch in batches:\n",
    "            loss = self.batch_loss(batch) / (self.update_every * self.batch_size)\n",
    "            \n",
    "            loss.backward()\n",
    "            loss_sum += loss\n",
    "            \n",
    "            # we're doing the accumulated gradients trick to get the gradients variance\n",
    "            # down while being able to use commodity GPU:\n",
    "            if batch.id % self.update_every == 0:\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                self.after_update(batch, loss_sum)\n",
    "                \n",
    "                loss_sum = 0\n",
    "    \n",
    "    def test(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def evaluate(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTrainer(BaseTrainer):\n",
    "    def __init__(self, name, nlp,\n",
    "                 summarize_model, discriminate_model, dataframe,\n",
    "                 batch_size, update_every, save_every, loader_workers,\n",
    "                 probability_of_mask_for_word,\n",
    "                 lambda_article, lambda_sentence):\n",
    "        super().__init__(\n",
    "            name, nlp,\n",
    "            summarize_model, discriminate_model, dataframe,\n",
    "            batch_size, update_every, save_every, loader_workers,\n",
    "            probability_of_mask_for_word,\n",
    "            lambda_article, lambda_sentence\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, articles_word_embeddings, orig_articles_word_embeddings,\n",
    "                     sentences_word_embeddings, orig_sentences_word_embeddings,\n",
    "                     sentences_numbers_in_articles,\n",
    "                     discriminate_articles_probs,\n",
    "                     discriminate_sentences_probs\n",
    "                    ):\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 81, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas.core.frame.DataFrame'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-c10853093eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTestTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummarizeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscriminatorNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-7213e084a11b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_every\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-7213e084a11b>\u001b[0m in \u001b[0;36mbatches\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     87\u001b[0m             )\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_batch_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 81, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "TestTrainer('test1', nlp, SummarizeNet(1024), DiscriminatorNet(), articles, 128, 128*100, 128*1000, 16, 0.2, 0.5, 0.5).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(BaseTrainer):\n",
    "    def __init__(self, name, nlp, summarize_model, discriminate_model, dataframe,\n",
    "                 batch_size, update_every, save_every, loader_workers,\n",
    "                 probability_of_mask_for_word, probability_of_masking_for_sample,\n",
    "                 lambda_article, lambda_sentence):\n",
    "        super().__init__(\n",
    "            name, nlp,\n",
    "            summarize_model, discriminate_model, dataframe,\n",
    "            batch_size, update_every, save_every, loader_workers,\n",
    "            lambda_article, lambda_sentence\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, articles_word_embeddings, orig_articles_word_embeddings,\n",
    "                     sentences_word_embeddings, orig_sentences_word_embeddings,\n",
    "                     sentences_numbers_in_articles,\n",
    "                     discriminate_articles_probs,\n",
    "                     discriminate_sentences_probs\n",
    "                    ):\n",
    "        articles_loss = F.cosine_embedding_loss(\n",
    "            articles_word_embeddings,\n",
    "            orig_articles_word_embeddings,\n",
    "            torch.ones(articles_word_embeddings.shape[0])\n",
    "        )\n",
    "        \n",
    "        sentences_loss = F.cosine_embedding_loss(\n",
    "            sentences_word_embeddings,\n",
    "            orig_sentences_word_embeddings,\n",
    "            torch.ones(articles_word_embeddings.shape[0])\n",
    "        ) / sentences_numbers_in_articles\n",
    "        \n",
    "        discriminator_articles_loss = F.binary_cross_entropy(\n",
    "            discriminate_articles_probs,\n",
    "            torch.zeros_like(discriminate_articles_probs)\n",
    "        )\n",
    "        \n",
    "        discriminator_sentences_loss = F.binary_cross_entropy(\n",
    "            discriminate_sentences_probs,\n",
    "            torch.zeros_like(discriminate_sentences_probs)\n",
    "        )\n",
    "        \n",
    "        return (articles_loss * self.lambda_article).sum(dim=0) +\n",
    "               (sentences_loss * self.lambda_sentence).sum(dim=0) +\n",
    "               discriminator_articles_loss +\n",
    "               discriminator_sentences_loss\n",
    "        \n",
    "\n",
    "    def batch_loss(self, batch):\n",
    "        # article -> article (de-noising)\n",
    "        articles_word_embeddings, articles_state = self.summarize_model(\n",
    "            batch.articles_noisy_word_embeddings,\n",
    "            generate=\"article\"\n",
    "        )\n",
    "\n",
    "        # headline -> headline (de-noising)\n",
    "        sentences_word_embeddings, sentences_state = self.summarize_model(\n",
    "            batch.sentences_noisy_word_embeddings,\n",
    "            generate=\"sentence\"\n",
    "        )\n",
    "\n",
    "        # the discriminator guessing which mode (article or sentence) was one state\n",
    "        # created for to deal with the \"segregation\" problem described in the paper:\n",
    "        discriminate_articles_probs = self.discriminate_model(articles_state)\n",
    "        discriminate_sentences_probs = self.discriminate_model(sentences_state)\n",
    "\n",
    "        # we're diverging from the article here by outputting the word embeddings\n",
    "        # instead of the probabilities for each word in a vocabulary\n",
    "        # our loss function is using the cosine embedding loss coupled with\n",
    "        # the discriminator loss:\n",
    "        return self.compute_loss(\n",
    "            articles_word_embeddings,\n",
    "            batch.articles_word_embeddings,\n",
    "\n",
    "            sentences_word_embeddings,\n",
    "            batch.sentences_word_embeddings,\n",
    "            batch.sentences_numbers_in_articles,\n",
    "\n",
    "            discriminate_articles_probs,\n",
    "            discriminate_sentences_probs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(articles, 8)\n",
    "\n",
    "for epoch in trainer.train():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
